from openai import OpenAI
from config import settings
import httpx
import tiktoken
import json

httpxClient = httpx.Client(verify=False)
client = OpenAI(
    http_client=httpxClient,
    api_key=settings.OPENAI_API_KEY,
)


def num_tokens_from_string(string: str, encoding_name: str) -> int:
    encoding = tiktoken.get_encoding(encoding_name)
    num_tokens = len(encoding.encode(string))
    return num_tokens


def xml_to_latex(input_xml_string: str) -> str:
    input_xml_string_cleaned = input_xml_string.replace("\n", "").replace("\\", "")
    if num_tokens_from_string(input_xml_string_cleaned, "cl100k_base") > 16000:
        return "Token limit exceeded"
    try:
        completion = client.chat.completions.create(
            model="gpt-3.5-turbo-16k-0613",
            messages=[
                {
                    "role": "system",
                    # "content": "convert this complex xml into simple Latex text. Just output the translation in Latex, no need to write any boilerplate code such as <usepackage> or <document>",
                    # "content": "convert this complex xml into regular text. If you encounter superscript, math equations, etc. write them in Latex format using tags from the 'amsmath' package. Strictly no other Latex code, because our output will not be compiled in the future.",
                    "content": "Convert this complex xml into regular text, and output a single string. If you encounter superscript, subscript, math symbols, equations, etc. write them in Latex format using tags from the 'amsmath' package. Strictly no other Latex code, because your output will not be compiled in the future.",
                },
                {"role": "user", "content": input_xml_string_cleaned},
            ],
        )
        return completion.choices[0].message.content
    except RuntimeError as e:
        return ""


def xml_to_latex_function_calling(input_xml_string: str) -> str:
    input_xml_string_cleaned = input_xml_string.replace("\n", "").replace("\\", "")
    if num_tokens_from_string(input_xml_string_cleaned, "cl100k_base") > 16000:
        return "Token limit exceeded"
    try:
        custom_functions = [
            {
                'name': 'extract_student_info',
                'description': "Convert this complex xml into regular text, and output a single string. If you encounter superscript, subscript, math symbols, equations, etc. write them in Latex format using tags from the 'amsmath' package. Strictly no other Latex code or extra text, because your output will not be compiled in the future.",
                'parameters': {
                    'type': 'object',
                    'properties': {
                        'simple_text': {
                            'type': 'string',
                            'description': 'clean simple text'
                        }
                    }
                }
            }
        ]
        completion = client.chat.completions.create(
            model='gpt-3.5-turbo',
            messages=[{'role': 'user', 'content': input_xml_string_cleaned}],
            functions=custom_functions,
            function_call='auto'
        )
        return json.loads(completion.choices[0].message.function_call.arguments)['simple_text']
    except RuntimeError as e:
        return ""

# print(xml_to_latex_function_calling('<div class="os-problem-container"> <p id="import-auto-id3575253">Construct the position graph for the subway shuttle train as shown in <a class="autogenerated-content" data-page-fragment="import-auto-id2590556" data-page-slug="2-4-acceleration" data-page-uuid="6023b87d-5a28-4910-9e51-ee7fd11c98e1" href="2-4-acceleration">Figure 2.18</a>(a). Your graph should show the position of the train, in kilometers, from t = 0 to 20 s. You will need to use the information on acceleration and velocity given in the examples for this figure. </p></div>'))
# print(xml_to_latex_function_calling('<div> B </div>'), xml_to_latex(('<div> B </div>')))